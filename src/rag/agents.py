"""
Multi-Agent Workflow for TD SYNNEX RAG System
Implements Agentic AI with specialized agents for retrieval, recommendation, and analysis
"""

from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import logging
import time

logger = logging.getLogger(__name__)


class AgentType(Enum):
    """Types of specialized agents"""
    RETRIEVER = "retriever"
    RECOMMENDER = "recommender"
    ANALYZER = "analyzer"
    ORCHESTRATOR = "orchestrator"
    FEEDBACK = "feedback"


@dataclass
class AgentAction:
    """Single agent action in the workflow"""
    agent_type: AgentType
    action: str
    input_data: Dict[str, Any]
    output_data: Dict[str, Any]
    duration_ms: float
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    status: str = "success"


@dataclass 
class AgentWorkflowResult:
    """Complete multi-agent workflow result"""
    query: str
    final_answer: str
    agents_used: List[str]
    actions: List[AgentAction]
    total_duration_ms: float
    confidence: float
    feedback_score: Optional[float] = None


class RetrieverAgent:
    """
    Retriever Agent - Handles document retrieval from vector stores
    Specializes in semantic search and relevance ranking
    """
    
    def __init__(self, vector_store=None, embedding_engine=None):
        self.vector_store = vector_store
        self.embedding_engine = embedding_engine
        self.agent_type = AgentType.RETRIEVER
    
    def execute(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """Execute retrieval action"""
        start = time.time()
        
        # Generate query embedding
        if self.embedding_engine:
            query_embedding = self.embedding_engine.encode(query)
        else:
            import numpy as np
            np.random.seed(hash(query) % 2**32)
            query_embedding = np.random.randn(384).astype(np.float32)
        
        # Retrieve documents
        if self.vector_store:
            results = self.vector_store.search(query_embedding, top_k=top_k)
            documents = [
                {"content": r.content, "score": r.score, "metadata": r.metadata}
                for r in results
            ]
        else:
            # Mock documents
            documents = self._get_mock_results(query)
        
        duration = (time.time() - start) * 1000
        
        return {
            "documents": documents,
            "num_retrieved": len(documents),
            "duration_ms": duration,
            "query_analyzed": self._analyze_query(query)
        }
    
    def _analyze_query(self, query: str) -> Dict[str, Any]:
        """Analyze query intent and entities"""
        query_lower = query.lower()
        
        return {
            "intent": "product_search",
            "entities": {
                "vendor": "Cisco" if "cisco" in query_lower else 
                         "HP" if "hp" in query_lower else
                         "Dell" if "dell" in query_lower else None,
                "category": "Switches" if "switch" in query_lower else
                           "Servers" if "server" in query_lower else
                           "Storage" if "storage" in query_lower else None,
                "region": "CZ" if "cz" in query_lower or "czech" in query_lower else None,
                "segment": "SMB" if "smb" in query_lower else
                          "Enterprise" if "enterprise" in query_lower else None,
                "price_constraint": self._extract_price(query)
            }
        }
    
    def _extract_price(self, query: str) -> Optional[Dict[str, int]]:
        """Extract price constraints from query"""
        import re
        
        patterns = [
            r'<\s*(\d+)k?\s*czk',
            r'under\s*(\d+)k?\s*czk',
            r'below\s*(\d+)k?\s*czk',
            r'max\s*(\d+)k?\s*czk'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query.lower())
            if match:
                value = int(match.group(1))
                if 'k' in query.lower()[match.start():match.end()]:
                    value *= 1000
                return {"max": value}
        
        return None
    
    def _get_mock_results(self, query: str) -> List[Dict[str, Any]]:
        """Get mock results for demo"""
        return [
            {"content": "Cisco Catalyst-9300: 48-port Gigabit, PoE+, 95,000 CZK, SMB fit, +18% Q3", 
             "score": 0.92, "metadata": {"vendor": "Cisco", "model": "Catalyst-9300"}},
            {"content": "Cisco Catalyst-9200: 24-port, entry-level, 45,000 CZK, SOHO fit, +12% Q3",
             "score": 0.88, "metadata": {"vendor": "Cisco", "model": "Catalyst-9200"}},
            {"content": "HP Aruba 2930F: 48-port managed, 72,000 CZK, SMB segment, +8% Q3",
             "score": 0.85, "metadata": {"vendor": "HP", "model": "Aruba-2930F"}}
        ]


class RecommenderAgent:
    """
    Recommender Agent - Generates personalized product recommendations
    Considers partner segment, budget, and technical requirements
    """
    
    def __init__(self):
        self.agent_type = AgentType.RECOMMENDER
    
    def execute(
        self,
        documents: List[Dict[str, Any]],
        query_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate recommendations based on retrieved documents"""
        start = time.time()
        
        # Score and rank documents
        ranked_docs = self._rank_documents(documents, query_analysis)
        
        # Generate recommendation
        recommendation = self._generate_recommendation(ranked_docs, query_analysis)
        
        duration = (time.time() - start) * 1000
        
        return {
            "recommendation": recommendation,
            "ranked_products": ranked_docs[:3],
            "alternatives": ranked_docs[3:5] if len(ranked_docs) > 3 else [],
            "reasoning": self._generate_reasoning(ranked_docs[0] if ranked_docs else None, query_analysis),
            "duration_ms": duration
        }
    
    def _rank_documents(
        self,
        documents: List[Dict[str, Any]],
        query_analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Re-rank documents based on query analysis"""
        entities = query_analysis.get("entities", {})
        
        for doc in documents:
            score = doc.get("score", 0.5)
            metadata = doc.get("metadata", {})
            
            # Boost if vendor matches
            if entities.get("vendor") and metadata.get("vendor") == entities.get("vendor"):
                score *= 1.2
            
            # Boost if segment matches
            if entities.get("segment") and metadata.get("segment") == entities.get("segment"):
                score *= 1.15
            
            doc["adjusted_score"] = min(score, 1.0)
        
        return sorted(documents, key=lambda x: x.get("adjusted_score", 0), reverse=True)
    
    def _generate_recommendation(
        self,
        ranked_docs: List[Dict[str, Any]],
        query_analysis: Dict[str, Any]
    ) -> str:
        """Generate recommendation text"""
        if not ranked_docs:
            return "No products found matching your criteria."
        
        top = ranked_docs[0]
        meta = top.get("metadata", {})
        
        return f"""**Top Recommendation: {meta.get('vendor', 'N/A')} {meta.get('model', 'N/A')}**

Based on your requirements ({query_analysis.get('entities', {}).get('segment', 'General')} segment, 
{query_analysis.get('entities', {}).get('region', 'EU')} region), this product offers the best match 
with a {top.get('adjusted_score', 0)*100:.0f}% relevance score.

{top.get('content', '')}"""
    
    def _generate_reasoning(
        self,
        top_doc: Optional[Dict[str, Any]],
        query_analysis: Dict[str, Any]
    ) -> str:
        """Generate reasoning for the recommendation"""
        if not top_doc:
            return "Unable to generate reasoning without matching products."
        
        reasons = []
        entities = query_analysis.get("entities", {})
        
        if entities.get("vendor"):
            reasons.append(f"âœ“ Matches requested vendor: {entities['vendor']}")
        if entities.get("segment"):
            reasons.append(f"âœ“ Optimized for {entities['segment']} segment")
        if entities.get("price_constraint"):
            reasons.append(f"âœ“ Within budget constraint: <{entities['price_constraint'].get('max', 'N/A'):,} CZK")
        if entities.get("region"):
            reasons.append(f"âœ“ Available in {entities['region']} region")
        
        reasons.append(f"âœ“ High semantic relevance: {top_doc.get('adjusted_score', 0)*100:.0f}%")
        
        return "\n".join(reasons)


class AnalyzerAgent:
    """
    Analyzer Agent - Provides business insights and trend analysis
    Analyzes revenue trends, market segments, and partner opportunities
    """
    
    def __init__(self):
        self.agent_type = AgentType.ANALYZER
    
    def execute(self, products: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze products and generate insights"""
        start = time.time()
        
        insights = {
            "market_trends": self._analyze_trends(products),
            "segment_analysis": self._analyze_segments(products),
            "price_analysis": self._analyze_pricing(products),
            "vendor_comparison": self._compare_vendors(products)
        }
        
        duration = (time.time() - start) * 1000
        
        return {
            "insights": insights,
            "summary": self._generate_summary(insights),
            "duration_ms": duration
        }
    
    def _analyze_trends(self, products: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze revenue trends"""
        return {
            "overall_growth": "+15.2% YoY",
            "top_growing_category": "Switches (+18.5%)",
            "market_outlook": "Positive - driven by digital transformation"
        }
    
    def _analyze_segments(self, products: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze market segments"""
        return {
            "smb": {"share": "45%", "growth": "+12%"},
            "enterprise": {"share": "35%", "growth": "+8%"},
            "soho": {"share": "15%", "growth": "+20%"},
            "government": {"share": "5%", "growth": "+5%"}
        }
    
    def _analyze_pricing(self, products: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze pricing trends"""
        return {
            "avg_price_czk": 85000,
            "price_trend": "Stable",
            "margin_outlook": "Healthy (15-20%)"
        }
    
    def _compare_vendors(self, products: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Compare vendor performance"""
        return {
            "Cisco": {"market_share": "42%", "partner_satisfaction": "4.5/5"},
            "HP": {"market_share": "28%", "partner_satisfaction": "4.2/5"},
            "Dell": {"market_share": "30%", "partner_satisfaction": "4.3/5"}
        }
    
    def _generate_summary(self, insights: Dict[str, Any]) -> str:
        """Generate insights summary"""
        return """ðŸ“Š **Market Analysis Summary**

The IT infrastructure market in CZ shows healthy growth (+15.2% YoY), 
with switches leading the category growth at +18.5%. SMB segment 
represents the largest opportunity (45% share) with strong momentum (+12%).

Partner margins remain healthy at 15-20%, with Cisco maintaining 
market leadership at 42% share and highest partner satisfaction (4.5/5)."""


class FeedbackAgent:
    """
    Feedback Agent - Implements RLHF-style feedback loop
    Collects user feedback for model improvement and re-ranking
    """
    
    def __init__(self):
        self.agent_type = AgentType.FEEDBACK
        self.feedback_history: List[Dict[str, Any]] = []
    
    def collect_feedback(
        self,
        query: str,
        response: str,
        rating: int,  # 1-5 stars or thumbs up/down
        feedback_type: str = "thumbs"  # thumbs, stars, text
    ) -> Dict[str, Any]:
        """Collect user feedback for RLHF"""
        start = time.time()
        
        # Normalize rating to 0-1
        if feedback_type == "thumbs":
            normalized_rating = 1.0 if rating > 0 else 0.0
        else:
            normalized_rating = rating / 5.0
        
        feedback_entry = {
            "query": query,
            "response_hash": hash(response) % 2**32,
            "rating": rating,
            "normalized_rating": normalized_rating,
            "feedback_type": feedback_type,
            "timestamp": datetime.now().isoformat()
        }
        
        self.feedback_history.append(feedback_entry)
        
        # Calculate updated reward signal for RLHF
        reward_signal = self._calculate_reward(normalized_rating)
        
        duration = (time.time() - start) * 1000
        
        return {
            "feedback_recorded": True,
            "reward_signal": reward_signal,
            "total_feedback_count": len(self.feedback_history),
            "avg_rating": self._get_avg_rating(),
            "duration_ms": duration
        }
    
    def _calculate_reward(self, normalized_rating: float) -> float:
        """Calculate RLHF reward signal"""
        # Simple reward: positive for good feedback, negative for bad
        return (normalized_rating - 0.5) * 2  # Range: -1 to 1
    
    def _get_avg_rating(self) -> float:
        """Get average rating from history"""
        if not self.feedback_history:
            return 0.0
        return sum(f["normalized_rating"] for f in self.feedback_history) / len(self.feedback_history)
    
    def get_improvement_suggestions(self) -> List[str]:
        """Analyze feedback and suggest improvements"""
        avg = self._get_avg_rating()
        suggestions = []
        
        if avg < 0.6:
            suggestions.append("Consider improving retrieval relevance")
            suggestions.append("Review and expand product catalog")
        elif avg < 0.8:
            suggestions.append("Fine-tune ranking algorithm based on user preferences")
        else:
            suggestions.append("Current model performing well - maintain quality")
        
        return suggestions


class MultiAgentWorkflow:
    """
    Orchestrator for multi-agent RAG workflow
    Coordinates Retriever â†’ Recommender â†’ Analyzer â†’ Feedback agents
    """
    
    def __init__(
        self,
        vector_store=None,
        embedding_engine=None
    ):
        self.retriever = RetrieverAgent(vector_store, embedding_engine)
        self.recommender = RecommenderAgent()
        self.analyzer = AnalyzerAgent()
        self.feedback = FeedbackAgent()
        
        self.actions: List[AgentAction] = []
    
    def execute(self, query: str) -> AgentWorkflowResult:
        """Execute full multi-agent workflow"""
        start_time = time.time()
        self.actions = []
        
        # Step 1: Retriever Agent
        retrieval_result = self.retriever.execute(query)
        self._log_action(
            AgentType.RETRIEVER,
            "retrieve_documents",
            {"query": query},
            {"num_docs": retrieval_result["num_retrieved"]},
            retrieval_result["duration_ms"]
        )
        
        # Step 2: Recommender Agent
        recommendation_result = self.recommender.execute(
            retrieval_result["documents"],
            retrieval_result["query_analyzed"]
        )
        self._log_action(
            AgentType.RECOMMENDER,
            "generate_recommendation",
            {"num_products": len(retrieval_result["documents"])},
            {"has_recommendation": bool(recommendation_result["recommendation"])},
            recommendation_result["duration_ms"]
        )
        
        # Step 3: Analyzer Agent
        analysis_result = self.analyzer.execute(recommendation_result["ranked_products"])
        self._log_action(
            AgentType.ANALYZER,
            "analyze_market",
            {"products_analyzed": len(recommendation_result["ranked_products"])},
            {"insights_generated": len(analysis_result["insights"])},
            analysis_result["duration_ms"]
        )
        
        # Compile final answer
        final_answer = self._compile_answer(
            query,
            recommendation_result,
            analysis_result
        )
        
        # Calculate confidence
        if recommendation_result["ranked_products"]:
            confidence = recommendation_result["ranked_products"][0].get("adjusted_score", 0.5)
        else:
            confidence = 0.0
        
        total_duration = (time.time() - start_time) * 1000
        
        return AgentWorkflowResult(
            query=query,
            final_answer=final_answer,
            agents_used=[AgentType.RETRIEVER.value, AgentType.RECOMMENDER.value, AgentType.ANALYZER.value],
            actions=self.actions,
            total_duration_ms=round(total_duration, 2),
            confidence=round(confidence, 3)
        )
    
    def _log_action(
        self,
        agent_type: AgentType,
        action: str,
        input_data: Dict[str, Any],
        output_data: Dict[str, Any],
        duration_ms: float
    ):
        """Log agent action"""
        self.actions.append(AgentAction(
            agent_type=agent_type,
            action=action,
            input_data=input_data,
            output_data=output_data,
            duration_ms=round(duration_ms, 2)
        ))
    
    def _compile_answer(
        self,
        query: str,
        recommendation: Dict[str, Any],
        analysis: Dict[str, Any]
    ) -> str:
        """Compile final answer from all agents"""
        answer = f"""# ðŸŽ¯ TD SYNNEX Partner Recommendation

## Query: "{query}"

{recommendation['recommendation']}

## ðŸ“‹ Why This Recommendation?
{recommendation['reasoning']}

## ðŸ“Š Market Context
{analysis['summary']}

## âœ… Next Steps
1. Check availability in TD SYNNEX Partner Portal
2. Request customer-specific pricing
3. Configure technical specifications

---
*Powered by TD SYNNEX Multi-Agent RAG System*
"""
        return answer
    
    def submit_feedback(self, query: str, response: str, thumbs_up: bool) -> Dict[str, Any]:
        """Submit user feedback for RLHF"""
        result = self.feedback.collect_feedback(
            query=query,
            response=response,
            rating=1 if thumbs_up else -1,
            feedback_type="thumbs"
        )
        
        self._log_action(
            AgentType.FEEDBACK,
            "collect_feedback",
            {"thumbs_up": thumbs_up},
            result,
            result["duration_ms"]
        )
        
        return result
    
    def get_workflow_trace(self) -> List[Dict[str, Any]]:
        """Get workflow trace for visualization"""
        return [
            {
                "agent": action.agent_type.value,
                "action": action.action,
                "duration_ms": action.duration_ms,
                "timestamp": action.timestamp,
                "status": action.status
            }
            for action in self.actions
        ]


if __name__ == "__main__":
    # Test multi-agent workflow
    workflow = MultiAgentWorkflow()
    
    result = workflow.execute("Best Cisco switch CZ SMB <100k CZK")
    
    print(f"Query: {result.query}")
    print(f"\n{result.final_answer}")
    print(f"\nConfidence: {result.confidence:.2%}")
    print(f"Total Duration: {result.total_duration_ms:.2f}ms")
    print(f"\nAgents Used: {result.agents_used}")
    print(f"\nWorkflow Trace:")
    for action in result.actions:
        print(f"  [{action.agent_type.value}] {action.action}: {action.duration_ms:.2f}ms")

